{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face-Mask-Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XepM28fS0TJGfKhl2tvuRpGnbaCifm7Q",
      "authorship_tag": "ABX9TyNNTr9g3vpNFYLRejlUHJEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngmars/Face-Mask-CNN/blob/master/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvRCAqB_eNhN",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfu2g1hfeFhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Z0Kr8TlkyC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh5BHlEDloXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path= r'/content/drive/My Drive/Colab Notebooks/Training Set'\n",
        "categories= os.listdir(data_path)\n",
        "labels= [i for i in range(len(categories))]\n",
        "\n",
        "label_dict= dict(zip(categories,labels))\n",
        "\n",
        "print (label_dict)\n",
        "for expression in os.listdir(\"/content/drive/My Drive/Colab Notebooks/Training Set\"):\n",
        "  print(str(len(os.listdir(\"/content/drive/My Drive/Colab Notebooks/Training Set/\"+ expression)))+ \" \" + expression + \" Images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGdjhdFmopG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "data= []\n",
        "target= []\n",
        "for category in categories:\n",
        "    folder_path= os.path.join(data_path, category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "    \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path, img_name)\n",
        "        img= cv2.imread(img_path)\n",
        "        \n",
        "        try:\n",
        "            resized= cv2.resize(img,(150,150))\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "        except Exception as e:\n",
        "            print(e)\"\"\"\n",
        "\n",
        "img_size= 150\n",
        "batch_size =64\n",
        "\n",
        "\n",
        "datagen_train= ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "train_data = datagen_train.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/Training Set/\", \n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "datagen_test= ImageDataGenerator(horizontal_flip=True)\n",
        "test_data = datagen_test.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/Test_set/\", \n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnPheuMfv7Qm",
        "colab_type": "text"
      },
      "source": [
        "Pre-trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVrpQ07kv9kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model= InceptionV3(input_shape= (150,150,3),\n",
        "                              include_top= False,\n",
        "                              weights= None)\n",
        "pre_trained_model.load_weights(r'/content/drive/My Drive/Colab Notebooks/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable= True\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m91-8SBAyTdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "last_layer= pre_trained_model.get_layer('mixed8')\n",
        "print(last_layer.output_shape)\n",
        "last_output= last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ6Ld3xkyjjh",
        "colab_type": "text"
      },
      "source": [
        "Building our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eamECAxYykLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "#Flatten output layer 1D\n",
        "x= layers.Flatten()(last_output)\n",
        "\n",
        "\n",
        "#Fully connected layer\n",
        "x= layers.Dense(1024)(x)\n",
        "x= layers.BatchNormalization()(x)\n",
        "x= layers.Activation('relu')(x)\n",
        "#Dropout due to overfitting\n",
        "x= layers.Dropout(0.2)(x)\n",
        "\n",
        "#Sigmoid for classification\n",
        "x= layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0005), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9-77vAx2vfE",
        "colab_type": "text"
      },
      "source": [
        "Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31J3aNoh3J4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \n",
        "\"\"\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=5)\n",
        "model.save_weights(checkpoint_path.format(epoch=10))\n",
        "\"\"\"\n",
        "epochs =1\n",
        "steps_per_epoch= train_data.n//train_data.batch_size\n",
        "test_steps=test_data.n//test_data.batch_size\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"model\", monitor='val_accuracy', save_weights_only=True,\n",
        "                            mode='max', verbose=1)\n",
        "reduce_lr= ReduceLROnPlateau(monitor='val_loss', factor= 0.1, patience=2, model='auto',min_lr=0.00001)\n",
        "callbacks= [ checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit(x= train_data, steps_per_epoch= steps_per_epoch, epochs= epochs, validation_data= test_data,validation_steps=test_steps, callbacks= callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}